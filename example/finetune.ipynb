{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from refuge.config import load_config\n",
    "from refuge.training import train, get_tokenizer_model_tokens_and_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(project=namespace(name='alice'),\n",
       "          model=namespace(hugging_face_name='databricks/dolly-v2-3b'),\n",
       "          prompt=namespace(initializer=\"Write an exerpt of a surreal children's fantasy story set in a subterranean world populated by peculiar anthropomorphic creatures. Go!\\n\\n\"),\n",
       "          training=namespace(block_size=700,\n",
       "                             checkpoint_interval=20,\n",
       "                             eval_interval=5,\n",
       "                             eval_blocks=8,\n",
       "                             batch_size=1,\n",
       "                             base_acc_steps=16,\n",
       "                             acc_doubling_rate=0,\n",
       "                             plateau_steps=0),\n",
       "          optimizer=namespace(lr=0.1,\n",
       "                              beta1=0.0,\n",
       "                              decay_rate=-0.8,\n",
       "                              weight_decay=0.1,\n",
       "                              scale_parameter=False,\n",
       "                              relative_step=False),\n",
       "          scheduler=namespace(num_warmup_steps=0,\n",
       "                              num_cycles=8,\n",
       "                              num_training_steps=6000))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_config()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/simon/git/refuge/example/checkpoints/dolly-v2-3b/alice/6021.csv\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = get_tokenizer_model_tokens_and_step(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?). worms CONSEQUENTIALancellor Der.— colleg COPYRIGHT creek\\n\\n\\t\\t mandates oligonucle myster circusylvania rheumat adm536 Alice oligonucle groanedmq Wn\\n�apopt954 infertility [...]---|---'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_tokens_for_soft_prompt = model.translated_soft_prompt()\n",
    "tokenizer.decode(nearest_tokens_for_soft_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eos_token_id = tokenizer.encode(\"### End\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "<|0|><|1|><|2|><|3|><|4|><|5|><|6|><|7|><|8|><|9|><|10|><|11|><|12|><|13|><|14|><|15|><|16|><|17|><|18|><|19|><|20|><|21|><|22|><|23|><|24|><|25|><|26|><|27|><|28|><|29|>\n",
      "\n",
      "### Response:\n",
      "Then I’ll take them off,” said Alice; and she took them both off, one at a time, very cautiously, for she had not the least idea what might be the consequences, but soon she was left entirely alone. “How very odd!” she said to herself. “I don’t believe I’ve ever done anything before that I should be thankful for! However, I’ll just see what it’ll come to! I hope it won’t be otherwise!” And she looked down into the cup to see what the next size would be.\n",
      "\n",
      "### End\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{model.soft_prompt}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "call = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "basic_output = model.generate(\n",
    "    input_ids=call,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_new_tokens=1024,\n",
    "    top_p=0.92,\n",
    "    do_sample=True,\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "print(tokenizer.decode(basic_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(cfg, tokenizer, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tuning_finetune_alice.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "3a36cc62f71b170ca22994dbd401744aeca204aa470bb3afe779afe0ab68d530"
  },
  "kernelspec": {
   "display_name": "refuge",
   "language": "python",
   "name": "refuge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "3a36cc62f71b170ca22994dbd401744aeca204aa470bb3afe779afe0ab68d530"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
